{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8020f2c17f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 1. Treat the data imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#TODO: \n",
    "# 1. Treat the data imbalance \n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from wandb.keras import WandbCallback\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from PIL import Image\n",
    "import skimage.transform\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from albumentations import (HorizontalFlip, Blur, VerticalFlip, Transpose, RandomCrop, \n",
    "                            RandomGamma, ShiftScaleRotate,\n",
    "                            HueSaturationValue, RGBShift, RandomBrightness, RandomContrast, CLAHE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(x, shape=(160,160,3)):\n",
    "    X_data_resized = [skimage.transform.resize(image, shape) for image in x]\n",
    "    \n",
    "    return np.array(X_data_resized)\n",
    "    \n",
    "def create_image_data(dataset, split, img_spec='std', shape=(160,160,3)):\n",
    "    #Raman Data/tox21/tox21-featurized/smiles2img/engd/index/train_dir/\n",
    "    #TODO: Add option for img_spec here. Path to dir changes accordingly\n",
    "    splits = ['train', 'test', 'valid']\n",
    "    if(split not in splits):\n",
    "        msg = 'split should be in: '+splits\n",
    "        return msg\n",
    "    \n",
    "    #BASE_DIR='Raman Data/'\n",
    "    path=dataset+'/'+dataset+'-featurized/smiles2img/'+img_spec+'/index/'+split+'_dir/'\n",
    "    print(path)\n",
    "    if(not os.path.exists(path)):\n",
    "        msg = \"Check path\"\n",
    "        return msg\n",
    "    \n",
    "    x0=joblib.load(path+'shard-0-X.joblib')\n",
    "    x0_resized = resize_images(x0, shape)\n",
    "    x1=joblib.load(path+'shard-1-X.joblib')\n",
    "    x1_resized = resize_images(x1, shape)\n",
    "    x2=joblib.load(path+'shard-2-X.joblib')\n",
    "    x2_resized = resize_images(x2, shape)\n",
    "    x3=joblib.load(path+'shard-3-X.joblib')\n",
    "    x3_resized = resize_images(x3, shape)\n",
    "    x4=joblib.load(path+'shard-4-X.joblib')\n",
    "    x4_resized = resize_images(x4, shape)\n",
    "    images=np.concatenate((x0_resized, x1_resized, x2_resized, x3_resized, x4_resized))    \n",
    "    \n",
    "    print(\"Images shape: \", images.shape)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(dataset, split, img_spec='std'):\n",
    "    #BASE_DIR='Raman Data/'\n",
    "    path=dataset+'/'+dataset+'-featurized/smiles2img/'+img_spec+'/index/'+split+'_dir/'\n",
    "    print(path)\n",
    "    if(not os.path.exists(path)):\n",
    "        msg = \"Check path\"\n",
    "        return msg\n",
    "    \n",
    "    y0=joblib.load(path+'shard-0-y.joblib')\n",
    "    y1=joblib.load(path+'shard-1-y.joblib')\n",
    "    y2=joblib.load(path+'shard-2-y.joblib')\n",
    "    y3=joblib.load(path+'shard-3-y.joblib')\n",
    "    y4=joblib.load(path+'shard-4-y.joblib')\n",
    "    labels=np.concatenate((y0, y1, y2, y3, y4))\n",
    "    print(\"Labels length: \", len(labels))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module(length=50, width=1):\n",
    "    lengths = [50, 101, 152]\n",
    "    widths = [1,3,4]\n",
    "    \n",
    "    if(length not in lengths or width not in widths):\n",
    "        msg = \"Length should be in \"+lengths+\"and width should be in \"+widths\n",
    "        return msg\n",
    "    \n",
    "    base_url = 'https://tfhub.dev/google/bit/'\n",
    "    model_url = base_url+'m-r'+str(length)+'x'+str(width)+'/1'\n",
    "    print(model_url)\n",
    "\n",
    "    module = hub.KerasLayer(model_url)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(aug, image):\n",
    "    aug_image = aug(image=image)['image']\n",
    "\n",
    "    return aug_image\n",
    "\n",
    "def get_balanced_data(x,y,shuffle=True):\n",
    "    minority_class=1\n",
    "    x = list(x)\n",
    "    y = list(y)\n",
    "    \n",
    "    augmented_x = []\n",
    "    augmented_y = []\n",
    "    \n",
    "    length = len(x)\n",
    "    for i in range(length):\n",
    "        if(int(y[i])==minority_class):\n",
    "            #Augment x\n",
    "            img = x[i]\n",
    "            aug1 = augment(RandomBrightness(p=1), img)\n",
    "            aug2 = augment(RandomContrast(p=1), img)\n",
    "            aug3 = augment(ShiftScaleRotate(p=1), img)\n",
    "            aug3 = augment(CLAHE(p=1), img)\n",
    "            aug4 = augment(HueSaturationValue(p=1), img)\n",
    "            aug5 = augment(Transpose(p=1), img)\n",
    "            \n",
    "            augmented_x.append(np.array(aug1))\n",
    "            augmented_x.append(np.array(aug2))\n",
    "            augmented_x.append(np.array(aug3))\n",
    "            augmented_x.append(np.array(aug4))\n",
    "            augmented_x.append(np.array(aug5))\n",
    "            \n",
    "            augmented_y.append(np.array(minority_class))\n",
    "            augmented_y.append(np.array(minority_class))\n",
    "            augmented_y.append(np.array(minority_class))\n",
    "            augmented_y.append(np.array(minority_class))\n",
    "            augmented_y.append(np.array(minority_class))\n",
    "            \n",
    "    x.append(augmented_x)\n",
    "    y.append(augmented_y)\n",
    "    \n",
    "    if(shuffle):\n",
    "        temp = list(zip(x, y)) \n",
    "        random.shuffle(temp) \n",
    "        x, y = zip(*temp) \n",
    "    \n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(\"Unique and counts: \", unique, counts)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8e9cfc4a6aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMyBiTModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m\"\"\"BiT with a new head.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class MyBiTModel(tf.keras.Model):\n",
    "  \"\"\"BiT with a new head.\"\"\"\n",
    "\n",
    "  def __init__(self, num_classes, module):\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_classes = num_classes\n",
    "    self.head1 = tf.keras.layers.Dense(512, kernel_initializer='zeros') #Necessary to initialize with zeros\n",
    "    self.head2 = tf.keras.layers.Dense(num_classes, kernel_initializer='zeros')\n",
    "    self.bit_model = module\n",
    "  \n",
    "  def call(self, images):\n",
    "    # No need to cut head off since we are using feature extractor model\n",
    "    bit_embedding = self.bit_model(images)\n",
    "    x1 = self.head1(bit_embedding)\n",
    "    x2 = self.head2(x1)\n",
    "    \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Train vs Validation Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raman Data/hiv/hiv-featurized/smiles2img/std/index/train_dir/\n",
      "Images length:  32757\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4fb9ddfc83da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hiv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hiv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "x_train, y_train = create_image_data(dataset='hiv', split='train', img_spec='std')\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_val, y_val = create_image_data(dataset='hiv', split='valid', img_spec='std')\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True), np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(data_len, img_size):\n",
    "    momentum=0.9\n",
    "    BATCH_SIZE=512\n",
    "    lr = 0.003 * BATCH_SIZE / 512\n",
    "    STEPS_PER_EPOCH = 10\n",
    "        \n",
    "    if(data_len<20000):\n",
    "        SCHEDULE_LENGTH=500\n",
    "        SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
    "    elif(data_len>=20000 and data_len<50000):\n",
    "        SCHEDULE_LENGTH=10000\n",
    "        SCHEDULE_BOUNDARIES = [3000, 6000, 9000]\n",
    "    else:\n",
    "        SCHEDULE_LENGTH = 20000\n",
    "        SCHEDULE_BOUNDARIES = [6000, 12000, 18000]\n",
    "    \n",
    "    SCHEDULE_LENGTH = SCHEDULE_LENGTH * 512 / BATCH_SIZE\n",
    "    SCHEDULE_BOUNDARIES = [int(0.3*SCHEDULE_LENGTH), int(0.6*SCHEDULE_LENGTH), int(0.9*SCHEDULE_LENGTH)]\n",
    "    \n",
    "    return momentum, BATCH_SIZE, lr, STEPS_PER_EPOCH, SCHEDULE_LENGTH, SCHEDULE_BOUNDARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIV Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load('Raman Data/hiv/hiv_images_std_resized_train.npy')\n",
    "x_val=np.load('Raman Data/hiv/hiv_images_std_resized_val.npy')\n",
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_labels('hiv', 'train', 'std')\n",
    "y_val = get_labels('hiv', 'valid', 'std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum, BATCH_SIZE, lr, STEPS_PER_EPOCH, SCHEDULE_LENGTH,SCHEDULE_BOUNDARIES = init_params(x_train.shape[0], x_train.shape[1])\n",
    "print(momentum, BATCH_SIZE, lr, STEPS_PER_EPOCH, SCHEDULE_LENGTH, SCHEDULE_BOUNDARIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES, \n",
    "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "opt2 = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=180,\n",
    "                        horizontal_flip=True,\n",
    "                        vertical_flip=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = get_module()\n",
    "model = MyBiTModel(num_classes=2, module=module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"summer-2020\", id=\"BiT_Transfer_hiv_imbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/Models/HIV/'\n",
    "model_name = 'ResNet50x1-BiT-Imbalanced.h5'\n",
    "mc = ModelCheckpoint(filepath=model_dir+model_name, monitor='val_loss', \n",
    "                     patience=5, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "es = EarlyStopping(patience=5, verbose=1, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model.fit(aug.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          steps_per_epoch = 10,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=[mc, es, WandbCallback(data_type=\"image\", validation_data=(x_val, y_val))])\n",
    "\n",
    "wandb.log({\"training_time\":time.time()-start})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
